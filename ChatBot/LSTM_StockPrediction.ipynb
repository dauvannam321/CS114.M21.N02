{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dauvannam321/CS114.M21.N02/blob/main/ChatBot/LSTM_StockPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3KCZTTEkQDf",
        "outputId": "4319fe5b-4e02-4959-9e94-af7f8ed27c41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (3.1.2)\n",
            "Requirement already satisfied: PyYAML<8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0)\n",
            "Requirement already satisfied: arrow<3.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.2.3)\n",
            "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.11.2)\n",
            "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (8.1.3)\n",
            "Requirement already satisfied: croniter<1.4.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.3.14)\n",
            "Requirement already satisfied: dateutils<2.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.6.12)\n",
            "Requirement already satisfied: deepdiff<8.0,>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.3.0)\n",
            "Requirement already satisfied: fastapi<0.89.0,>=0.69.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.88.0)\n",
            "Requirement already satisfied: fsspec<2024.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.4.0)\n",
            "Requirement already satisfied: inquirer<5.0,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (3.1.3)\n",
            "Requirement already satisfied: lightning-cloud>=0.5.34 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.5.36)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.8.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lightning) (23.1)\n",
            "Requirement already satisfied: psutil<7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (5.9.5)\n",
            "Requirement already satisfied: pydantic<4.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.10.7)\n",
            "Requirement already satisfied: requests<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.27.1)\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (13.3.4)\n",
            "Requirement already satisfied: starlette in /usr/local/lib/python3.10/dist-packages (from lightning) (0.22.0)\n",
            "Requirement already satisfied: starsessions<2.0,>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.3.0)\n",
            "Requirement already satisfied: torch<4.0,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.11.4)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.65.0)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (5.7.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.26.15)\n",
            "Requirement already satisfied: uvicorn<2.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.22.0)\n",
            "Requirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.5.1)\n",
            "Requirement already satisfied: websockets<12.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (11.0.3)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.4.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateutils<2.0->lightning) (2022.7.1)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff<8.0,>=5.7.0->lightning) (4.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->lightning) (3.6.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec<2024.0,>=2022.5.0->lightning) (3.8.4)\n",
            "Requirement already satisfied: blessed>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning) (1.20.0)\n",
            "Requirement already satisfied: python-editor>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning) (1.0.4)\n",
            "Requirement already satisfied: readchar>=3.0.6 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning) (4.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<5.0->lightning) (2.1.2)\n",
            "Requirement already satisfied: pyjwt in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.34->lightning) (2.7.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.34->lightning) (0.0.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.34->lightning) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning) (2.14.0)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning) (16.0.5)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn<2.0->lightning) (0.14.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\n",
            "Requirement already satisfied: setuptools>=41.0 in /usr/local/lib/python3.10/dist-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (67.7.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.11.0->lightning) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUh0fc-uj54i"
      },
      "outputs": [],
      "source": [
        "import torch #  Dùng torch để tạo ra tensor lưu data\n",
        "import torch.nn as nn # torch.nn để tạo mới mạng neural .\n",
        "import torch.nn.functional as F #sử dụng các thư viện loss và optimization\n",
        "from torch.optim import Adam # Sử dụng để để tìm optimization\n",
        "\n",
        "import lightning as L # thư viện hỗ trợ phá triển nhanh mạng neural network\n",
        "from torch.utils.data import TensorDataset, DataLoader # hỗ trợ thao tác trên dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bp06x2oslDS-"
      },
      "outputs": [],
      "source": [
        "## Here we are implementing an LSTM network by hand...\n",
        "class LSTMbyHand(L.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # khơi tạo weights sử dụng normal distribution\n",
        "        mean = torch.tensor(0.0)\n",
        "        std = torch.tensor(1.0)\n",
        "\n",
        "        self.wlr1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "\n",
        "        self.wlr2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "\n",
        "        self.blr1 = nn.Parameter(torch.tensor(0.), requires_grad=True)\n",
        "\n",
        "        ## These are the Weights and Biases in the second stage, which determins the new\n",
        "        ## potential long-term memory and what percentage will be remembered.\n",
        "        self.wpr1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "        self.wpr2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "        self.bpr1 = nn.Parameter(torch.tensor(0.), requires_grad=True)\n",
        "\n",
        "        self.wp1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "        self.wp2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "        self.bp1 = nn.Parameter(torch.tensor(0.), requires_grad=True)\n",
        "\n",
        "        ## These are the Weights and Biases in the third stage, which determines the\n",
        "        ## new short-term memory and what percentage will be sent to the output.\n",
        "        self.wo1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "        self.wo2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "        self.bo1 = nn.Parameter(torch.tensor(0.), requires_grad=True)\n",
        "\n",
        "\n",
        "    def lstm_unit(self, input_value, long_memory, short_memory):\n",
        "\n",
        "        long_remember_percent = torch.sigmoid((short_memory * self.wlr1) +\n",
        "                                              (input_value * self.wlr2) +\n",
        "                                              self.blr1)\n",
        "\n",
        "        ## 2) The second stage creates a new, potential long-term memory and determines what\n",
        "        ##    percentage of that to add to the current long-term memory\n",
        "        potential_remember_percent = torch.sigmoid((short_memory * self.wpr1) +\n",
        "                                                   (input_value * self.wpr2) +\n",
        "                                                   self.bpr1)\n",
        "        potential_memory = torch.tanh((short_memory * self.wp1) +\n",
        "                                      (input_value * self.wp2) +\n",
        "                                      self.bp1)\n",
        "\n",
        "        ## Once we have gone through the first two stages, we can update the long-term memory\n",
        "        updated_long_memory = ((long_memory * long_remember_percent) +\n",
        "                       (potential_remember_percent * potential_memory))\n",
        "\n",
        "        ## 3) The third stage creates a new, potential short-term memory and determines what\n",
        "        ##    percentage of that should be remembered and used as output.\n",
        "        output_percent = torch.sigmoid((short_memory * self.wo1) +\n",
        "                                       (input_value * self.wo2) +\n",
        "                                       self.bo1)\n",
        "        updated_short_memory = torch.tanh(updated_long_memory) * output_percent\n",
        "\n",
        "        ## Finally, we return the updated long and short-term memories\n",
        "        return([updated_long_memory, updated_short_memory])\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        long_memory = 0 # long term memory is also called \"cell state\" and indexed with c0, c1, ..., cN\n",
        "        short_memory = 0 # short term memory is also called \"hidden state\" and indexed with h0, h1, ..., cN\n",
        "        day1 = input[0]\n",
        "        day2 = input[1]\n",
        "        day3 = input[2]\n",
        "        day4 = input[3]\n",
        "\n",
        "        ## Day 1\n",
        "        long_memory, short_memory = self.lstm_unit(day1, long_memory, short_memory)\n",
        "\n",
        "        ## Day 2\n",
        "        long_memory, short_memory = self.lstm_unit(day2, long_memory, short_memory)\n",
        "\n",
        "        ## Day 3\n",
        "        long_memory, short_memory = self.lstm_unit(day3, long_memory, short_memory)\n",
        "\n",
        "        ## Day 4\n",
        "        long_memory, short_memory = self.lstm_unit(day4, long_memory, short_memory)\n",
        "\n",
        "        ##### Now return short_memory, which is the 'output' of the LSTM.\n",
        "        return short_memory\n",
        "\n",
        "\n",
        "    def configure_optimizers(self): # this configures the optimizer we want to use for backpropagation.\n",
        "        # return Adam(self.parameters(), lr=0.1) # NOTE: Setting the learning rate to 0.1 trains way faster than\n",
        "                                                 # using the default learning rate, lr=0.001, which requires a lot more\n",
        "                                                 # training. However, if we use the default value, we get\n",
        "                                                 # the exact same Weights and Biases that I used in\n",
        "                                                 # the LSTM Clearly Explained StatQuest video. So we'll use the\n",
        "                                                 # default value.\n",
        "        return Adam(self.parameters())\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx): # take a step during gradient descent.\n",
        "        input_i, label_i = batch # collect input\n",
        "        output_i = self.forward(input_i[0]) # run input through the neural network\n",
        "        loss = (output_i - label_i)**2 ## loss = squared residual\n",
        "\n",
        "        ###################\n",
        "        ##\n",
        "        ## Logging the loss and the predicted values so we can evaluate the training\n",
        "        ##\n",
        "        ###################\n",
        "        self.log(\"train_loss\", loss)\n",
        "        ## NOTE: Our dataset consists of two sequences of values representing Company A and Company B\n",
        "        ## For Company A, the goal is to predict that the value on Day 5 = 0, and for Company B,\n",
        "        ## the goal is to predict that the value on Day 5 = 1. We use label_i, the value we want to\n",
        "        ## predict, to keep track of which company we just made a prediction for and\n",
        "        ## log that output value in a company specific file\n",
        "        if (label_i == 0):\n",
        "            self.log(\"out_0\", output_i)\n",
        "        else:\n",
        "            self.log(\"out_1\", output_i)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJV_AykePgc9",
        "outputId": "ebf47b28-edf6-4235-eb4d-c2859cabeacc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before optimization, the parameters are...\n",
            "wlr1 tensor(-0.6707)\n",
            "wlr2 tensor(0.8398)\n",
            "blr1 tensor(0.)\n",
            "wpr1 tensor(0.0119)\n",
            "wpr2 tensor(0.3017)\n",
            "bpr1 tensor(0.)\n",
            "wp1 tensor(-1.0404)\n",
            "wp2 tensor(1.5843)\n",
            "bp1 tensor(0.)\n",
            "wo1 tensor(-0.9482)\n",
            "wo2 tensor(2.2892)\n",
            "bo1 tensor(0.)\n",
            "\n",
            "Now let's compare the observed and predicted values...\n",
            "Company A: Observed = 0, Predicted = tensor(0.5307)\n",
            "Company B: Observed = 1, Predicted = tensor(0.5414)\n"
          ]
        }
      ],
      "source": [
        "## Create the model object, print out parameters and see how well\n",
        "## the untrained LSTM can make predictions...\n",
        "model = LSTMbyHand()\n",
        "\n",
        "print(\"Before optimization, the parameters are...\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.data)\n",
        "\n",
        "print(\"\\nNow let's compare the observed and predicted values...\")\n",
        "## NOTE: To make predictions, we pass in the first 4 days worth of stock values\n",
        "## in an array for each company. In this case, the only difference between the\n",
        "## input values for Company A and B occurs on the first day. Company A has 0 and\n",
        "## Company B has 1.\n",
        "print(\"Company A: Observed = 0, Predicted =\",\n",
        "      model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\n",
        "print(\"Company B: Observed = 1, Predicted =\",\n",
        "      model(torch.tensor([1., 0.5, 0.25, 1.])).detach())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqAPi5I4QTDx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjOgzO4xPukI"
      },
      "source": [
        "Train the LSTM unit and use Lightning and TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578,
          "referenced_widgets": [
            "f44621fe802840c3b9c077bf2ba507da",
            "ed22f1b5d4274076918807894ca1f21f",
            "b458bb72918442f790f040bc96b31d3d",
            "14852a58caf649098a0be84f0a1a8b18",
            "572e1d40e4bf4f05b06aaf5f8e3f02c6",
            "e93c394e6d294b6ea26cb1f0a816bf04",
            "64f34455a70a49f69c69b360d48f4599",
            "d9ebf0ecc98d47f283cc77c21e98ae3e",
            "74065879b22c44e4bda324114a060358",
            "081c091a7aaa47dea2b446098009d2d6",
            "99bebde43b3f4db6bb19161eb14fefdd"
          ]
        },
        "id": "_K2AcnztQUey",
        "outputId": "5fa7c57a-8bd6-4da1-930b-1bae11789ce2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: \n",
            "  | Name | Type | Params\n",
            "------------------------------\n",
            "------------------------------\n",
            "12        Trainable params\n",
            "0         Non-trainable params\n",
            "12        Total params\n",
            "0.000     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name | Type | Params\n",
            "------------------------------\n",
            "------------------------------\n",
            "12        Trainable params\n",
            "0         Non-trainable params\n",
            "12        Total params\n",
            "0.000     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f44621fe802840c3b9c077bf2ba507da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=5000` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5000` reached.\n"
          ]
        }
      ],
      "source": [
        "## create the training data for the neural network.\n",
        "inputs = torch.tensor([[0., 0.5, 0.25, 1.], [1., 0.5, 0.25, 1.]])\n",
        "labels = torch.tensor([0., 1.])\n",
        "\n",
        "dataset = TensorDataset(inputs, labels)\n",
        "dataloader = DataLoader(dataset)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=5000) # with default learning rate, 0.001 (this tiny learning rate makes learning slow)\n",
        "trainer.fit(model, train_dataloaders=dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWL8ekXTQ6SQ",
        "outputId": "ef8b09cd-576d-4294-ce47-5bfd3e07cacb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Now let's compare the observed and predicted values...\n",
            "Company A: Observed = 0, Predicted = tensor(6.4408e-05)\n",
            "Company B: Observed = 1, Predicted = tensor(0.9841)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nNow let's compare the observed and predicted values...\")\n",
        "print(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\n",
        "print(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq5-UGNQLR3r"
      },
      "source": [
        "\n",
        "Using and optimzing the PyTorch LSTM, nn.LSTM()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBv1qlmhLQ-7"
      },
      "outputs": [],
      "source": [
        "## Instead of coding an LSTM by hand, let's see what we can do with PyTorch's nn.LSTM()\n",
        "class LightningLSTM(L.LightningModule):\n",
        "\n",
        "    def __init__(self): # __init__() is the class constructor function, and we use it to initialize the Weights and Biases.\n",
        "\n",
        "        super().__init__() # initialize an instance of the parent class, LightningModule.\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=1, hidden_size=1)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        ## transpose the input vector\n",
        "        input_trans = input.view(len(input), 1)\n",
        "\n",
        "        lstm_out, temp = self.lstm(input_trans)\n",
        "\n",
        "        ## lstm_out has the short-term memories for all inputs. We make our prediction with the last one\n",
        "        prediction = lstm_out[-1]\n",
        "        return prediction\n",
        "\n",
        "\n",
        "    def configure_optimizers(self): # this configures the optimizer we want to use for backpropagation.\n",
        "        return Adam(self.parameters(), lr=0.1) ## we'll just go ahead and set the learning rate to 0.1\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx): # take a step during gradient descent.\n",
        "        input_i, label_i = batch # collect input\n",
        "        output_i = self.forward(input_i[0]) # run input through the neural network\n",
        "        loss = (output_i - label_i)**2 ## loss = squared residual\n",
        "\n",
        "        ###################\n",
        "        ##\n",
        "        ## Logging the loss and the predicted values so we can evaluate the training\n",
        "        ##\n",
        "        ###################\n",
        "        self.log(\"train_loss\", loss)\n",
        "\n",
        "        if (label_i == 0):\n",
        "            self.log(\"out_0\", output_i)\n",
        "        else:\n",
        "            self.log(\"out_1\", output_i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9Blgh0DMM2G",
        "outputId": "caf6a58f-1524-4f31-9dea-9453f0fc9640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before optimization, the parameters are...\n",
            "lstm.weight_ih_l0 tensor([[ 0.2484],\n",
            "        [-0.1472],\n",
            "        [-0.7297],\n",
            "        [ 0.7463]])\n",
            "lstm.weight_hh_l0 tensor([[-0.2210],\n",
            "        [ 0.3663],\n",
            "        [ 0.7424],\n",
            "        [ 0.3357]])\n",
            "lstm.bias_ih_l0 tensor([ 0.3517, -0.8898,  0.0106,  0.8547])\n",
            "lstm.bias_hh_l0 tensor([-0.7946,  0.0859,  0.1643,  0.2480])\n",
            "\n",
            "Now let's compare the observed and predicted values...\n",
            "Company A: Observed = 0, Predicted = tensor([-0.2038])\n",
            "Company B: Observed = 1, Predicted = tensor([-0.2357])\n"
          ]
        }
      ],
      "source": [
        "model = LightningLSTM() # First, make model from the class\n",
        "\n",
        "## print out the name and value for each parameter\n",
        "print(\"Before optimization, the parameters are...\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.data)\n",
        "\n",
        "print(\"\\nNow let's compare the observed and predicted values...\")\n",
        "print(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\n",
        "print(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 782,
          "referenced_widgets": [
            "a3314b44514342359777d5080bb3a89b",
            "165689c07b124897a71cc1ddd706b2ea",
            "e1de484598c84de58d89ba1c111fb5bc",
            "0c0a64cfdccc4fc084254029c2d9b5e7",
            "668a677b8f7f4a61b26d6c1c2617ca67",
            "622b3fc516b54736b0efbcd4df7e4d31",
            "7ba56ce4ffaf4db1bd42aeda45ff91ee",
            "535451decdb3412a809ab7d50d4af887",
            "c2387e943ae64a57ab82c4ec6e7949c6",
            "9f1d907db63348998d7bf8fc20e0db52",
            "887bc3901a1540e9b3bfc6835b56f31c"
          ]
        },
        "id": "qhX7FSotMamD",
        "outputId": "73256550-1a0e-4752-8764-e34e033a63ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: \n",
            "  | Name | Type | Params\n",
            "------------------------------\n",
            "0 | lstm | LSTM | 16    \n",
            "------------------------------\n",
            "16        Trainable params\n",
            "0         Non-trainable params\n",
            "16        Total params\n",
            "0.000     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name | Type | Params\n",
            "------------------------------\n",
            "0 | lstm | LSTM | 16    \n",
            "------------------------------\n",
            "16        Trainable params\n",
            "0         Non-trainable params\n",
            "16        Total params\n",
            "0.000     Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3314b44514342359777d5080bb3a89b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/optimization/automatic.py:129: UserWarning: `training_step` returned `None`. If this was on purpose, ignore this warning...\n",
            "  self.warning_cache.warn(\"`training_step` returned `None`. If this was on purpose, ignore this warning...\")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "inputs = torch.tensor([[0., 0.5, 0.25, 1.], [1., 0.5, 0.25, 1.]])\n",
        "labels = torch.tensor([0., 1.])\n",
        "\n",
        "dataset = TensorDataset(inputs, labels)\n",
        "dataloader = DataLoader(dataset)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=300, log_every_n_steps=2)\n",
        "\n",
        "trainer.fit(model, train_dataloaders=dataloader)\n",
        "\n",
        "print(\"After optimization, the parameters are...\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYEWTbF_Odfb"
      },
      "outputs": [],
      "source": [
        "print(\"\\nNow let's compare the observed and predicted values...\")\n",
        "print(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\n",
        "print(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "081c091a7aaa47dea2b446098009d2d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0a64cfdccc4fc084254029c2d9b5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f1d907db63348998d7bf8fc20e0db52",
            "placeholder": "​",
            "style": "IPY_MODEL_887bc3901a1540e9b3bfc6835b56f31c",
            "value": " 1/2 [00:00&lt;00:00, 106.31it/s, v_num=6]"
          }
        },
        "14852a58caf649098a0be84f0a1a8b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_081c091a7aaa47dea2b446098009d2d6",
            "placeholder": "​",
            "style": "IPY_MODEL_99bebde43b3f4db6bb19161eb14fefdd",
            "value": " 2/2 [00:00&lt;00:00, 52.44it/s, v_num=5]"
          }
        },
        "165689c07b124897a71cc1ddd706b2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_622b3fc516b54736b0efbcd4df7e4d31",
            "placeholder": "​",
            "style": "IPY_MODEL_7ba56ce4ffaf4db1bd42aeda45ff91ee",
            "value": "Epoch 278: 100%"
          }
        },
        "535451decdb3412a809ab7d50d4af887": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572e1d40e4bf4f05b06aaf5f8e3f02c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "622b3fc516b54736b0efbcd4df7e4d31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f34455a70a49f69c69b360d48f4599": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "668a677b8f7f4a61b26d6c1c2617ca67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "74065879b22c44e4bda324114a060358": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ba56ce4ffaf4db1bd42aeda45ff91ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "887bc3901a1540e9b3bfc6835b56f31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99bebde43b3f4db6bb19161eb14fefdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f1d907db63348998d7bf8fc20e0db52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3314b44514342359777d5080bb3a89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_165689c07b124897a71cc1ddd706b2ea",
              "IPY_MODEL_e1de484598c84de58d89ba1c111fb5bc",
              "IPY_MODEL_0c0a64cfdccc4fc084254029c2d9b5e7"
            ],
            "layout": "IPY_MODEL_668a677b8f7f4a61b26d6c1c2617ca67"
          }
        },
        "b458bb72918442f790f040bc96b31d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9ebf0ecc98d47f283cc77c21e98ae3e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74065879b22c44e4bda324114a060358",
            "value": 2
          }
        },
        "c2387e943ae64a57ab82c4ec6e7949c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9ebf0ecc98d47f283cc77c21e98ae3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1de484598c84de58d89ba1c111fb5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_535451decdb3412a809ab7d50d4af887",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2387e943ae64a57ab82c4ec6e7949c6",
            "value": 2
          }
        },
        "e93c394e6d294b6ea26cb1f0a816bf04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed22f1b5d4274076918807894ca1f21f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e93c394e6d294b6ea26cb1f0a816bf04",
            "placeholder": "​",
            "style": "IPY_MODEL_64f34455a70a49f69c69b360d48f4599",
            "value": "Epoch 4999: 100%"
          }
        },
        "f44621fe802840c3b9c077bf2ba507da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed22f1b5d4274076918807894ca1f21f",
              "IPY_MODEL_b458bb72918442f790f040bc96b31d3d",
              "IPY_MODEL_14852a58caf649098a0be84f0a1a8b18"
            ],
            "layout": "IPY_MODEL_572e1d40e4bf4f05b06aaf5f8e3f02c6"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}