{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Crawler.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMaP84VKByEFqr/0Yo6EKQp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goldenspring6622/CS114.M21.N02/blob/main/Data_Crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chat_downloader"
      ],
      "metadata": {
        "id": "PUmcFleh7usL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4xfm4TL7pTZ"
      },
      "outputs": [],
      "source": [
        "#Import package\n",
        "import chat_downloader #Thank xenova for creating this fookin vjppr0 lib\n",
        "from chat_downloader import ChatDownloader\n",
        "import os\n",
        "import re\n",
        "from openpyxl import Workbook #Now prepare a xlsx to write crawl data\n",
        "wb = Workbook()\n",
        "# grab the active worksheet\n",
        "ws = wb.active\n",
        "# Data can be assigned directly to cells\n",
        "ws['A1'] = 'Content'\n",
        "ws['A2'] = 'Final'\n",
        "#Now copy and paste something like\n",
        "url = 'https://www.youtube.com/watch?v=Ejzw6Htgj7c'#Only the football live stream which has chat replay\n",
        "chat = ChatDownloader().get_chat(url=url,start_time=None,end_time=None)#Get chats from url\n",
        "d = 0\n",
        "lst = []\n",
        "# Create a generator\n",
        "for message in chat:\n",
        "\t\"\"\"Crawled chat should be like this\n",
        "\t{\n",
        "    ...\n",
        "    \"message_id\": \"xxxxxxxxxx\",\n",
        "    \"message\": \"actual message goes here\",\n",
        "    \"message_type\": \"text_message\",\n",
        "    \"timestamp\": 1613761152565924,\n",
        "    \"time_in_seconds\": 1234.56,\n",
        "    \"time_text\": \"20:34\",\n",
        "    \"author\": {\n",
        "        \"id\": \"UCxxxxxxxxxxxxxxxxxxxxxxx\",\n",
        "        \"name\": \"username_of_sender\",\n",
        "        \"images\": [\n",
        "            ...\n",
        "        ],\n",
        "        \"badges\": [\n",
        "            ...\n",
        "        ]\n",
        "    },\n",
        "    ...\n",
        "}\"\"\"\n",
        "\t#In here we just get 7000 messages\n",
        "\t#if(d>7000):break\n",
        "\tif (len(message['message'])>1):# iterate over messages\n",
        "\t\t\tstr = message['message']#Just take message content\n",
        "\t\t\timport re\n",
        "\t\t\ta = re.findall(':.*?:', str)#We will remove all emote, which start and end with char ':'\n",
        "\t\t\tfor sub in a:\n",
        "\t\t\t\tstr = str.replace(sub, '')\n",
        "\t\t\t# Now we try to remove all the same message content by create a substring without space char and check if it existed, write to file\n",
        "\t\t\tst=str.replace(' ','')\n",
        "\t\t\tif (str!='' and lst.count(st)==0):\n",
        "\t\t\t   ws.append([str])\n",
        "\t\t\t   lst.append(st)\n",
        "\t\t\t   d = d + 1\n",
        "wb.save(\"DataCrawl.xlsx\")\n"
      ]
    }
  ]
}